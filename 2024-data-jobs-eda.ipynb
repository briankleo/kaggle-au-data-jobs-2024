{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4739706,"sourceType":"datasetVersion","datasetId":2397749}],"dockerImageVersionId":30715,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Australia Data Science Jobs - Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"## Set up notebook","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom fuzzywuzzy import process\npd.set_option('display.max_rows', None)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-01T03:15:52.755533Z","iopub.execute_input":"2024-06-01T03:15:52.755978Z","iopub.status.idle":"2024-06-01T03:15:52.762152Z","shell.execute_reply.started":"2024-06-01T03:15:52.755943Z","shell.execute_reply":"2024-06-01T03:15:52.760926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## read input csv and convert to datasets","metadata":{}},{"cell_type":"code","source":"file1 = r'/kaggle/input/australia-data-science-jobs/AustraliaDataScienceJobs.csv'\nfile2 = r'/kaggle/input/australia-data-science-jobs/AustraliaDataScienceJob2.csv'\n\n# Re-importing datasets and checking for data issues\ndf1 = pd.read_csv(file1)\ndf2 = pd.read_csv(file2)\n\n# Combine the datasets\ndf = pd.concat([df1, df2])","metadata":{"execution":{"iopub.status.busy":"2024-06-01T03:15:54.967266Z","iopub.execute_input":"2024-06-01T03:15:54.967707Z","iopub.status.idle":"2024-06-01T03:15:55.175781Z","shell.execute_reply.started":"2024-06-01T03:15:54.967648Z","shell.execute_reply":"2024-06-01T03:15:55.174592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fuzzy match job titles","metadata":{}},{"cell_type":"code","source":"# Checking for non-string values in 'Job Title' column\ndf['Job Title'] = df['Job Title'].astype(str)\n\n# Define the categories and their possible titles\ncategories = {\n    \"Data Analyst\": [\"data analyst\"],\n    \"Data Engineer\": [\"data engineer\"],\n    \"Data Scientist\": [\"data scientist\"]\n}\n\n# Function to classify job title\ndef classify_job_title(title):\n    best_match = None\n    highest_score = 0\n    \n    for category, titles in categories.items():\n        match, score = process.extractOne(title, titles)\n        if score > highest_score:\n            highest_score = score\n            best_match = category\n    \n    return best_match if highest_score >= 70 else \"Other Analyst\"\n\ndf['Job Category'] = df['Job Title'].apply(classify_job_title)","metadata":{"execution":{"iopub.status.busy":"2024-06-01T03:16:01.753251Z","iopub.execute_input":"2024-06-01T03:16:01.753665Z","iopub.status.idle":"2024-06-01T03:16:06.929343Z","shell.execute_reply.started":"2024-06-01T03:16:01.753622Z","shell.execute_reply":"2024-06-01T03:16:06.928158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Count and Ave. Salary by Job","metadata":{}},{"cell_type":"code","source":"# Calculate average salary and count per job category\naverage_salary_count = df.groupby('Job Category')['High Estimate'].agg(['mean', 'count']).reset_index()\naverage_salary_count.columns = ['Job Category', 'Average Salary', 'Job Count']\n\n# Format the output to make it prettier\naverage_salary_count['Average Salary'] = average_salary_count['Average Salary'].apply(lambda x: f\"${x:,.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-01T03:16:06.931562Z","iopub.execute_input":"2024-06-01T03:16:06.931926Z","iopub.status.idle":"2024-06-01T03:16:06.944565Z","shell.execute_reply.started":"2024-06-01T03:16:06.931893Z","shell.execute_reply":"2024-06-01T03:16:06.942947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"average_salary_count","metadata":{"execution":{"iopub.status.busy":"2024-06-01T03:16:06.945892Z","iopub.execute_input":"2024-06-01T03:16:06.946288Z","iopub.status.idle":"2024-06-01T03:16:06.966634Z","shell.execute_reply.started":"2024-06-01T03:16:06.946254Z","shell.execute_reply":"2024-06-01T03:16:06.965246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Skills by job","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Extract skill columns\nskill_columns = [col for col in df.columns if col.endswith('_yn')]\n\n# Calculate skill percentages per job category\nskill_percentages = df.groupby('Job Category')[skill_columns].mean() * 100\nskill_percentages = skill_percentages.reset_index()\n\n# Rename columns\nskill_percentages.columns = ['Job Category'] + [col.replace('_yn', '') for col in skill_percentages.columns if col != 'Job Category']\n\n# Round percentages to 2 decimal places\nskill_percentages = skill_percentages.round(2)\n\n# Transpose the data to have job titles as columns and skills as rows\nskill_percentages_pivot = skill_percentages.set_index('Job Category').transpose()","metadata":{"execution":{"iopub.status.busy":"2024-06-01T03:16:12.958766Z","iopub.execute_input":"2024-06-01T03:16:12.959175Z","iopub.status.idle":"2024-06-01T03:16:12.973915Z","shell.execute_reply.started":"2024-06-01T03:16:12.959144Z","shell.execute_reply":"2024-06-01T03:16:12.972564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pct of time skill is mentioned per job","metadata":{}},{"cell_type":"code","source":"# Display the result\nskill_percentages_pivot","metadata":{"execution":{"iopub.status.busy":"2024-06-01T03:16:13.342184Z","iopub.execute_input":"2024-06-01T03:16:13.342565Z","iopub.status.idle":"2024-06-01T03:16:13.367075Z","shell.execute_reply.started":"2024-06-01T03:16:13.342536Z","shell.execute_reply":"2024-06-01T03:16:13.365750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Salary and Job count by Company ","metadata":{}},{"cell_type":"code","source":"# Calculate average salary and count per company\ncompany_salary_count = df.groupby('Company')['High Estimate'].agg(['mean', 'count']).reset_index()\ncompany_salary_count.columns = ['Company', 'Average Salary', 'Job Count']\n\n# Format the salary and sort by job count\ncompany_salary_count['Average Salary'] = company_salary_count['Average Salary'].apply(lambda x: f\"${int(x):,}\")\ncompany_salary_count = company_salary_count.sort_values(by='Job Count', ascending=False).reset_index(drop=True)\n\n# Display the result\ncompany_salary_count","metadata":{"execution":{"iopub.status.busy":"2024-06-01T03:16:13.846369Z","iopub.execute_input":"2024-06-01T03:16:13.847257Z","iopub.status.idle":"2024-06-01T03:16:13.935719Z","shell.execute_reply.started":"2024-06-01T03:16:13.847217Z","shell.execute_reply":"2024-06-01T03:16:13.934465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ave. Salary by Job and Company","metadata":{}},{"cell_type":"code","source":"# Create a pivot table with job titles as columns, companies as rows, and average salary as values\npivot_table = df.pivot_table(index='Company', columns='Job Category', values='High Estimate', aggfunc='mean')\n\n# Format the salaries to integer with commas\npivot_table = pivot_table.applymap(lambda x: f\"${int(x):,}\" if pd.notnull(x) else '-')\n\n# Display the result\npivot_table","metadata":{"execution":{"iopub.status.busy":"2024-06-01T03:16:14.027082Z","iopub.execute_input":"2024-06-01T03:16:14.027997Z","iopub.status.idle":"2024-06-01T03:16:14.137717Z","shell.execute_reply.started":"2024-06-01T03:16:14.027961Z","shell.execute_reply":"2024-06-01T03:16:14.136628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Job Count by Job and Company","metadata":{}},{"cell_type":"code","source":"# Create a pivot table with job titles as columns, companies as rows, and job count as values\npivot_table_counts = df.pivot_table(index='Company', columns='Job Category', values='Job Title', aggfunc='count', fill_value=0)\n\n# Display the result\npivot_table_counts","metadata":{"execution":{"iopub.status.busy":"2024-06-01T03:16:14.837427Z","iopub.execute_input":"2024-06-01T03:16:14.837826Z","iopub.status.idle":"2024-06-01T03:16:14.925351Z","shell.execute_reply.started":"2024-06-01T03:16:14.837793Z","shell.execute_reply":"2024-06-01T03:16:14.924216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}